from typing import Dict, Any, Tuple

import pickle

import os

import itertools
import random
import math

from lightning import LightningDataModule
from datasets import Audio, load_dataset
from torch.utils.data import DataLoader

from lightning.pytorch.utilities import CombinedLoader


class SPKVLightningDataModule(LightningDataModule):

    DATASET_NAME = "Cnam-LMSSC/vibravox_enhanced_by_EBEN_dummy" # For tests only, replace it by vibravox later

    def __init__(
        self,
        pklfile_path: str,
        sample_rate: int = 16000,
        sensor_a: str = "airborne.mouth_headworn.reference_microphone",
        sensor_b: str = "airborne.mouth_headworn.reference_microphone",
        subset: str = "speech_clean",
        split: str = "test",
        streaming: bool = False,
        batch_size: int = 1,
        num_workers: int = 4,
    ):
        """
        LightningDataModule for Speaker Verification (SPKV)

        Args:
            sample_rate (int, optional): Sample rate at which the dataset is output. Defaults to 16000.
            sensor_a (str, optional): Sensor. Defaults to ("airborne.mouth_headworn.reference_microphone").
            sensor_b (str, optional): Sensor. Defaults to ("airborne.mouth_headworn.reference_microphone").
            subset (str, optional): Subset. Defaults to ("speech_clean").
            split (str, optional) : Split. Defaults to "test".
            pklfile_path (str, optional): Pickle file path. Defaults to "configs/lightning_datamodule/misc/pairs.pkl".
            streaming (bool, optional): If True, the audio files are dynamically downloaded. Defaults to False.
            batch_size (int, optional): Batch size. Defaults to 1 since ECAPA2 pretrained model only supports this Batchsize
            num_workers (int, optional): Number of workers. Defaults to 4.
        """
        super().__init__()

        self.sample_rate = sample_rate
        self.sensorA = sensor_a
        self.sensorB = sensor_b
        self.subset = subset
        self.split = split
        self.pklfile_path = pklfile_path
        self.streaming = streaming
        self.batch_size = batch_size
        self.num_workers = num_workers

    def setup(self, stage=None):
        """
        Set up the datasets.

        Args:
            stage (str): Pipeline stage among ['fit', 'validate', 'test', 'predict']. Defaults to None.

        Notes:
            This function runs on every accelerator in distributed mode.
            That is why it is necessary to define attributes here rather than in __init__.
        """

        print("Loading the dataset ...")
        dataset_dict = load_dataset(
            self.DATASET_NAME, self.subset, split=self.split, streaming=self.streaming
        )

        print("Ordering by speaker_id ...")
        # Order by speaker_id for easier pairing of audios :
        dataset_dict = dataset_dict.sort("speaker_id")

        print("Selecting columns for dataset_dict_a ... ")

        # Only keep the relevant columns for this task :
        dataset_dict_a = dataset_dict.select_columns([f"audio.{self.sensorA}","speaker_id", "sentence_id"])
        dataset_dict_b = dataset_dict.select_columns([f"audio.{self.sensorB}","speaker_id", "sentence_id"])

        print("Resampling the audios to the right sample rate ...")

        # Resample the audios to the right sample rate
        dataset_dict_a = dataset_dict_a.cast_column(
            f"audio.{self.sensorA}", Audio(sampling_rate=self.sample_rate, mono=False)
        )

        dataset_dict_b = dataset_dict_b.cast_column(
            f"audio.{self.sensorB}", Audio(sampling_rate=self.sample_rate, mono=False)
        )

        # Load the config/misc/pairs.pkl file generated by scripts/gen_pairs_for_spkv.py :

        with open(self.pklfile_path, 'rb') as file:
            pairs = pickle.load(file)

        print("Selecting the audios for the test dataset A and B  ...")
        dataset_dict_a = dataset_dict_a.select([pair[0] for pair in pairs])
        dataset_dict_b = dataset_dict_b.select([pair[1] for pair in pairs])

        print("Renaming columns ...")

        dataset_dict_a = dataset_dict_a.rename_column(f"audio.{self.sensorA}", "audio")
        dataset_dict_b = dataset_dict_b.rename_column(f"audio.{self.sensorB}", "audio")


        print("Setting format to torch ...")

        dataset_dict_a = dataset_dict_a.with_format("torch")

        print(dataset_dict_a.shape)
        dataset_dict_b = dataset_dict_b.with_format("torch")
        print(dataset_dict_a.shape)


        self.test_dataset_a = dataset_dict_a
        self.test_dataset_b = dataset_dict_b

    def train_dataloader(self):
        """
        Train dataloader. Since SPKV does not have a training set, we return an empty dataloader.

        Returns:
            Nothing
        """

        pass

    def val_dataloader(self):
        """
        Validation dataloader. Since SPKV does not have a validation set, we return an empty dataloader.

        Returns:
            Nothing
        """

        pass

    def test_dataloader(self):
        """
        Test dataloader.

        Returns:
            Collection of two DataLoaders corresponding to dataset_A and dataset_B
        """

        return CombinedLoader({"a" : DataLoader(self.test_dataset_a ,batch_size=self.batch_size,num_workers=self.num_workers,collate_fn=self.data_collator,),
                           "b": DataLoader(self.test_dataset_b,batch_size=self.batch_size,num_workers=self.num_workers,collate_fn=self.data_collator,)},
                          'min_size')


    def data_collator(self, batch: Dict[str, Any]) -> Dict[str, Any]:
        """
        Custom data collator function to extract the array from the Audio feature.

        Args:
            batch: Dict from the dataset with the keys "audio" , "speaker_id" , and "sentence_id"
        Returns:
            dict
        """

        audio = [sample["audio"]["array"] for sample in batch]
        speaker_id = [sample["speaker_id"] for sample in batch]
        sentence_id = [sample["sentence_id"] for sample in batch]

        return {
            "audio": audio,
            "speaker_id": speaker_id,
            "sentence_id": sentence_id,
        }